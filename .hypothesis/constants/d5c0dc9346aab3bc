# file: C:\Users\Edwin Boston\AppData\Roaming\Python\Python314\site-packages\transformers\modeling_utils.py
# hypothesis_version: 6.150.2

[0.0, 1e-09, 0.02, 1.0, 1.2, 500, 1024, '(.*?)-\\d{5}-of-\\d{5}', '*', ',', '-1', '.', '.*.', '.bin', '.index', '.safetensors', '/', '0', '0.29.0', '0.31', '0.31.4', '0.43.2', '1.10', '1.7.0', '2', '2.0.4', '2.1.0', '2.3', '2.3.0', '2.4.1', '2.5', '5GB', '8', 'AutoModel', 'BF16', 'BOOL', 'F16', 'F32', 'F64', 'F8_E4M3', 'F8_E5M2', 'FSDP', 'ForCausalLM', 'GenerationMixin', 'I16', 'I32', 'I64', 'I8', 'LOCAL_RANK', 'LayerNorm', 'LayerNorm.beta', 'LayerNorm.bias', 'LayerNorm.gamma', 'LayerNorm.weight', 'ModuleUtilsMixin', 'PreTrainedModel', 'README.md', 'RMSNorm', 'U16', 'U32', 'U64', 'U8', 'WORLD_SIZE', 'XLA_DOWNCAST_BF16', 'XLA_USE_BF16', '\\(.*\\)', '\\.\\d+\\.', '\\d+', '^', '__annotations__', '_adapter_model_path', '_attn_was_changed', '_commit_hash', '_compiled_call', '_ep_plan', '_extra_state', '_fast_init', '_from_auto', '_from_pipeline', '_hf_hook', '_hf_tp_plan', '_input_embed_layer', '_is_hf_initialized', '_is_hooked', '_last_compile_config', '_loss_function', '_pp_plan', '_tie_weights', '_tied_weights_keys', '_tp_plan', '_use_kernels', 'accelerate', 'adapter_kwargs', 'adapter_name', 'alibi', 'all_checkpoint_keys', 'aria', 'attention_dropout', 'attn_implementation', 'auto', 'ayavision', 'balanced', 'balanced_low_0', 'base_model_prefix', 'bias', 'bitsandbytes', 'cache_dir', 'can_generate', 'casting_dtype', 'colpali', 'commit_message', 'compile_config', 'config', 'config_class', 'constant', 'constant_', 'cpu', 'create_pr', 'cuda', 'decoder', 'default', 'device', 'device_map', 'device_mesh', 'disk', 'distributed_config', 'dtype', 'eager', 'eager_paged', 'element_size', 'embed_tokens', 'empty_param', 'emu3', 'encoder', 'error_msgs', 'estimate_tokens', 'file_type', 'flash_attention', 'flash_attention_2', 'flash_attention_3', 'flash_attn', 'flash_attn_3', 'flax', 'flex_attention', 'float32', 'float8_e4m3fn', 'force_download', 'force_hooks', 'format', 'framework', 'from_auto_class', 'from_flax', 'from_tf', 'fuyu', 'gemma3', 'generation_config', 'get_decoder', 'get_extra_state', 'gguf_file', 'gotocr2', 'hf_device_map', 'hf_quantizer', 'initializer_range', 'input_ids', 'internvl', 'is_encoder_decoder', 'is_loaded_in_4bit', 'is_loaded_in_8bit', 'is_quantized', 'kaiming_normal', 'kaiming_normal_', 'kaiming_uniform', 'kaiming_uniform_', 'key_mapping', 'llama4', 'llava', 'lm_head', 'load_custom_generate', 'load_in_4bit', 'load_in_8bit', 'local_files_only', 'local_packed_rowwise', 'loss_type', 'low_cpu_mem_usage', 'main', 'max_memory', 'mem_rss_diff', 'meta', 'metadata', 'mirror', 'mismatched_keys', 'missing_keys', 'mistral3', 'mllama', 'mlx', 'mmap', 'model', 'model file', 'module', 'named_parameters', 'normal', 'normal_', 'num_embeddings', 'offload_buffers', 'offload_dir', 'offload_folder', 'offload_index', 'offload_state_dict', 'out_features', 'output_loading_info', 'paged_attention', 'paligemma', 'proxies', 'pt', 'pytorch', 'quant_storage', 'quantization_config', 'quantization_method', 'qwen2_5_vl', 'qwen2vl', 'r', 'rank', 'recursive', 'repo_id', 'requires_grad', 'resume_download', 'revision', 'rotary_emb.inv_freq', 'rotary_emb\\.inv_freq', 'safetensors_file', 'save_config', 'sdpa', 'sdpa_paged', 'sequential', 'set_decoder', 'shieldgemma2', 'size mismatch', 'skip_keys', 'smart_apply', 'special_dtypes', 'state_dict', 'subfolder', 'tags', 'tensors', 'tf', 'tie_encoder_decoder', 'tie_word_embeddings', 'to_contiguous', 'token', 'torch.', 'torch_dtype', 'total_parameters', 'tp', 'tp_plan', 'tp_size', 'transformers_weights', 'true', 'trunc_normal_', 'trust_remote_code', 'unexpected_keys', 'uniform', 'uniform_', 'use_alibi', 'use_auth_token', 'use_kernels', 'use_reentrant', 'user_agent', 'using_pipeline', 'utf-8', 'value', 'variant', 'version', 'videollava', 'vipllava', 'w', 'warnings_issued', 'weight', 'weight_g', 'weight_map', 'weight_name', 'weight_norm', 'weight_v', 'xavier_normal', 'xavier_normal_', 'xavier_uniform', 'xavier_uniform_', 'xpu', '{suffix}.bin', '{suffix}.safetensors', '|']