# file: C:\Users\Edwin Boston\AppData\Roaming\Python\Python314\site-packages\transformers\modeling_gguf_pytorch_utils.py
# hypothesis_version: 6.150.2

['.', '.attn_k.', '.attn_q.', '.bias', '.weight', 'GGUF', 'T5EncoderModel', 'UMT5EncoderModel', '_exp', 'architectures', 'attn_k.bias', 'attn_output.weight', 'attn_q.bias', 'attn_qkv', 'attn_qkv.weight', 'attn_v.bias', 'bid', 'bloom', 'cohere', 'command-r', 'config', 'falcon', 'ffn_down.weight', 'ffn_gate_inp_shexp', 'ffn_norm', 'ffn_up.weight', 'file_type', 'full_attn_idxs', 'gemma2', 'gemma3', 'gemma3_text', 'general', 'general.architecture', 'general.name', 'gpt2', 'hidden_size', 'ignore', 'is_gated_act', 'kv_count', 'lfm2', 'llama', 'lm_head.weight', 'mamba', 'mistral', 'mlp.experts.', 'mlp.experts.\\d+.', 'model_type', 'n_head', 'nemotron', 'norm.weight', 'num_attention_heads', 'num_experts', 'num_key_value_heads', 'output.weight', 'parsed_parameters', 'quantization_version', 'qwen2_moe', 'qwen2moe', 'qwen3_moe', 'qwen3moe', 'ssm_a', 'ssm_conv1d.weight', 'stablelm', 't5', 't5encoder', 'tensor_count', 'tensor_key_mapping', 'tensors', 'tie_word_embeddings', 'tokenizer', 'tokenizer_config', 'tokens', 'umt5', 'use_qkv_bias', 'version', 'vocab_size', 'weight']