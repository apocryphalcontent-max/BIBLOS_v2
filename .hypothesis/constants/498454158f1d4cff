# file: C:\Users\Edwin Boston\AppData\Roaming\Python\Python314\site-packages\transformers\integrations\flash_attention.py
# hypothesis_version: 6.150.2

[0.0, 'head_mask', 'is_causal', 'layer_idx', 'output_attentions']