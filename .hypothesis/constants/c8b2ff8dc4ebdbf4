# file: C:\Users\Edwin Boston\AppData\Roaming\Python\Python314\site-packages\transformers\models\bert\tokenization_bert.py
# hypothesis_version: 6.150.2

[100, 13312, 19903, 19968, 40959, 63744, 64255, 65533, 131072, 173791, 173824, 177983, 177984, 178207, 178208, 183983, 194560, 195103, ' ##', '##', '-', 'BasicTokenizer', 'BertTokenizer', 'Mn', 'NFC', 'NFD', 'WordpieceTokenizer', '[CLS]', '[MASK]', '[PAD]', '[SEP]', '[UNK]', 'r', 'utf-8', 'vocab.txt', 'vocab_file', 'w']