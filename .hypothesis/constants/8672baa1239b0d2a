# file: C:\Users\Edwin Boston\AppData\Roaming\Python\Python314\site-packages\transformers\configuration_utils.py
# hypothesis_version: 6.150.2

[0.0, 1.0, ',', '.', '.json', '0', '1', '=', 'AutoConfig', 'PretrainedConfig', '_attention_heads', '_attn_implementation', '_auto_class', '_commit_hash', '_configuration_file', '_from_auto', '_from_pipeline', '_layers', '_name_or_path', '_output_attentions', 'attn_implementation', 'attribute_map', 'bad_words_ids', 'base_model_pp_plan', 'base_model_tp_plan', 'cache_dir', 'chunked_attention', 'commit_message', 'config', 'config.', 'config.json', 'configuration file', 'configuration_files', 'decoder', 'diversity_penalty', 'do_sample', 'dtype', 'eager', 'early_stopping', 'encoder', 'false', 'file_type', 'force_download', 'forced_bos_token_id', 'forced_eos_token_id', 'from_auto_class', 'full_attention', 'generator', 'gguf_file', 'id2label', 'length_penalty', 'linear_attention', 'local_files_only', 'main', 'max_length', 'min_length', 'model_type', 'n', 'name_or_path', 'no', 'no_repeat_ngram_size', 'num_attention_heads', 'num_beam_groups', 'num_beams', 'num_hidden_layers', 'num_labels', 'num_return_sequences', 'output_attentions', 'output_scores', 'proxies', 'pruned_heads', 'quantization_config', 'regression', 'repetition_penalty', 'repo_id', 'resume_download', 'return_unused_kwargs', 'revision', 'sliding_attention', 'subfolder', 'suppress_tokens', 'temperature', 'text_config', 'text_encoder', 'tf_legacy_loss', 'timm_wrapper', 'token', 'top_k', 'top_p', 'torch.dtype', 'torch_dtype', 'transformers_version', 'transformers_weights', 'true', 'trust_remote_code', 'typical_p', 'use_auth_token', 'use_bfloat16', 'using_pipeline', 'utf-8', 'vocab_file', 'w', 'y', 'yes']